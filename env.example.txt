# CLOUD MODE ENABLED (required)

## - true
## - false

# Determines wether the application mode is cloud or local. If cloud mode is enabled, the classes and conundrums will be fetched from the Minio S3 bucket. If cloud mode is disabled, the classes and conundrums will be fetched from the local file system. If cloud mode is enabled, the following variables are required:

# S3_BUCKET_ENDPOINT
# S3_BUCKET_ACCESS_KEY
# S3_BUCKET_ACCESS_SECRET
# S3_BUCKET_NAME
# S3_BUCKET_PATH

CLOUD_MODE=false

# S3 BUCKET STORAGE

# When cloud mode is enabled the classes and conundrums will be fetched from a S3 bucket.

S3_BUCKET_ENDPOINT=
S3_BUCKET_ACCESS_KEY=
S3_BUCKET_ACCESS_SECRET=
S3_BUCKET_NAME=
S3_BUCKET_PATH=""

# MAILGUN

# This is the configuration for the Mailgun API. This is used to send emails with the conversation summaries to the users.

MAILGUN_ENABLED=false

# If MAILGUN_ENABLED is set to true, the following variables are required:

MAILGUN_API_KEY=
MAILGUN_API_URL=
MAILGUN_FROM_ADDRESS="Name <email@example.com>"

# PYPPETEER CHROMIUM VERSION

# This is the version of Chromium that will be used by Pyppeteer. This is required for generating the pdfs of the conversation summaries.

## Windows - 1410486
## MacOS - 1410497
## Linux - 1410505

PYPPETEER_CHROMIUM_REVISION=

# MODEL PROVIDER (required)

##  - OPENAI
##  - GOOGLE
##  - IBM
##  - ANTHROPIC (not supported yet)
##  - OLLAMA (not supported yet)

MODEL_PROVIDER=

# MODEL SELECTION (required)

# You can use any of the following models:

## OpenAI
##  - chatgpt-4o-latest (tested)
##  - gpt-4o-mini
##  - o1-preview
##  - o1-mini
##  - gpt-4-turbo
##  - gpt-3.5-turbo

## Google
##  - gemini-1.5-pro (tested)
##  - gemini-1.5-flash

## IBM
##  - ibm/granite-34b-code-instruct (tested)
##  - meta-llama/llama-3-2-90b-vision-instruct (tested)

## Anthropic
##  - claude-3-5-sonnet-latest (tested, not supported yet)

## Ollama
##  - llama3.2 (tested, not supported yet)

MODEL=

# API KEY (required, if using a provider other than Google)
# Enter your API key for the selected model provider
API_KEY=

# GOOGLE_APPLICATION_CREDENTIALS (required, if using Google as provider)
# Set the path to your Google Cloud credentials file (JSON)
GOOGLE_APPLICATION_CREDENTIALS=

# IBM_URL (required, if using IBM as provider)
# Set the URL for the IBM Cloud ML service
IBM_URL=

# IBM_PROJECT_ID (required, if using IBM as provider)
# Set the project ID for the IBM Cloud ML service
IBM_PROJECT_ID=

# MAX_TOKENS (optional)
# Set the maximum number of tokens to generate
MAX_TOKENS=

# MAX_RETRIES (optional)
# Set the maximum number of retries for LLM requests
MAX_RETRIES=

# TIMEOUT (optional)
# Set the timeout for LLM requests
TIMEOUT=

# TEMPERATURE (optional)
# Set the temperature for sampling
TEMPERATURE=

# TOP_P (optional)
# Set the nucleus sampling parameter
TOP_P=

# FREQUENCY_PENALTY (optional)
# Set the frequency penalty parameter
FREQUENCY_PENALTY=

# PRESENCE_PENALTY (optional)
# Set the presence penalty parameter
PRESENCE_PENALTY=
